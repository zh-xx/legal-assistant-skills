#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ‡å‡†åˆåŒå®¡æ ¸å·¥ä½œæµç¨‹
Contract Review Standard Workflow

æä¾›å®Œæ•´çš„åˆåŒå®¡æ ¸æµç¨‹,åŒ…æ‹¬:
- æ™ºèƒ½åˆåŒåˆ†æ
- è§£åŒ…æ–‡æ¡£
- åˆå§‹åŒ–Documentå¯¹è±¡
- æ‰¹é‡æ·»åŠ æ‰¹æ³¨(æ”¯æŒå¤šå…³é”®è¯æœç´¢)
- è‡ªåŠ¨éªŒè¯æ‰¹æ³¨
- ä¿å­˜å¹¶æ‰“åŒ…æ–‡æ¡£
- ç”ŸæˆåˆåŒæ¦‚è¦
- ç”Ÿæˆä¸šåŠ¡æµç¨‹å›¾(Mermaid)å¹¶æ¸²æŸ“å›¾ç‰‡
- ç”Ÿæˆå®¡æ ¸æŠ¥å‘Š

ä½¿ç”¨ç¤ºä¾‹:
    from scripts.workflow import ContractReviewWorkflow

    comments = [
        {
            "search": ["åˆåŒæ€»ä»·", "åè®®æ€»é‡‘é¢", "æ€»é‡‘é¢"],
            "comment": "ã€é—®é¢˜ç±»å‹ã€‘åˆåŒä»·æ¬¾æ¡æ¬¾\\nã€é£é™©ç­‰çº§ã€‘ğŸ”´ é«˜é£é™©..."
        }
    ]

    workflow = ContractReviewWorkflow("åˆåŒ.docx", "å®¡æ ¸äºº")
    workflow.run_full_workflow(comments, "åˆåŒ_å®¡æ ¸ç‰ˆ.docx")
"""

import sys
import os
import shutil
import zipfile
import xml.etree.ElementTree as ET
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ·»åŠ æŠ€èƒ½è·¯å¾„
skill_dir = Path(__file__).parent.parent
if str(skill_dir) not in sys.path:
    sys.path.insert(0, str(skill_dir))

try:
    from scripts.contract_analyzer import ContractAnalyzer
except ImportError:
    from contract_analyzer import ContractAnalyzer

from scripts.document import Document
from scripts.summary_renderer import render_summary_docx
from scripts.opinion_renderer import render_opinion_docx
from scripts.mermaid_renderer import (
    normalize_mermaid_code,
    render_mermaid_file,
    write_mermaid_file,
)
from scripts.ooxml.unpack import unpack_document
from scripts.ooxml.pack import pack_document


def _detect_output_language(*texts: Optional[str]) -> Optional[str]:
    combined = "\n".join([text for text in texts if text])
    if not combined:
        return None
    cjk_count = 0
    latin_count = 0
    for char in combined:
        if "\u4e00" <= char <= "\u9fff":
            cjk_count += 1
        elif "A" <= char <= "Z" or "a" <= char <= "z":
            latin_count += 1
    if cjk_count == 0 and latin_count == 0:
        return None
    if cjk_count >= latin_count:
        return "zh"
    return "en"


def _detect_output_language_from_contract(contract_path: Path) -> Optional[str]:
    try:
        with zipfile.ZipFile(contract_path) as zf:
            xml = zf.read("word/document.xml")
    except Exception:
        return None

    try:
        root = ET.fromstring(xml)
    except Exception:
        return None

    ns = {"w": "http://schemas.openxmlformats.org/wordprocessingml/2006/main"}
    texts = []
    for node in root.findall(".//w:t", ns):
        if node.text:
            texts.append(node.text)
    combined = "".join(texts)
    return _detect_output_language(combined)


_CN_SECTION_LABELS = {
    1: "ä¸€",
    2: "äºŒ",
    3: "ä¸‰",
    4: "å››",
    5: "äº”",
    6: "å…­",
    7: "ä¸ƒ",
    8: "å…«",
    9: "ä¹",
    10: "å",
}


def _section_cn(index: int) -> str:
    return _CN_SECTION_LABELS.get(index, str(index))


class ContractReviewWorkflow:
    """
    å®Œæ•´çš„åˆåŒå®¡æ ¸å·¥ä½œæµç¨‹

    è¯¥ç±»å°è£…äº†åˆåŒå®¡æ ¸çš„æ‰€æœ‰æ­¥éª¤,ç¡®ä¿æ¯ä¸ªæ­¥éª¤éƒ½æ­£ç¡®æ‰§è¡Œ,
    å¹¶æä¾›è¯¦ç»†çš„åé¦ˆå’ŒéªŒè¯æœºåˆ¶ã€‚
    """

    def __init__(
        self,
        contract_path: str,
        reviewer_name: str = "åˆåŒå®¡æ ¸åŠ©æ‰‹",
        output_dir: str = None,
        enable_analysis: bool = True,
        enable_smart_keyword_expansion: bool = False,
    ):
        """
        åˆå§‹åŒ–å·¥ä½œæµç¨‹

        Args:
            contract_path: åˆåŒæ–‡æ¡£è·¯å¾„(.docxæ–‡ä»¶)
            reviewer_name: å®¡æ ¸äººå§“å,ç”¨äºæ‰¹æ³¨ä½œè€…
            output_dir: è¾“å‡ºç›®å½•(å¦‚æœä¸ºNone,è‡ªåŠ¨åˆ›å»º"å®¡æ ¸ç»“æœï¼šã€ŒåŸåˆåŒæ–‡ä»¶åã€"æ–‡ä»¶å¤¹)
            enable_analysis: æ˜¯å¦å¯ç”¨æ™ºèƒ½åˆåŒåˆ†æ(é»˜è®¤True)
            enable_smart_keyword_expansion: æ˜¯å¦å¯ç”¨æ™ºèƒ½å…³é”®è¯æ‰©å±•(é»˜è®¤False)
        """
        self.contract_path = Path(contract_path)
        self.reviewer_name = reviewer_name
        self.reviewer_initials = "å®¡æ ¸"
        self.enable_analysis = enable_analysis
        self.enable_smart_keyword_expansion = enable_smart_keyword_expansion
        self.output_language = None
        self.output_dir_default = output_dir is None

        # å¦‚æœæœªæŒ‡å®šè¾“å‡ºç›®å½•,åˆ›å»ºå®¡æ ¸ç»“æœæ–‡ä»¶å¤¹
        if output_dir is None:
            original_name = self.contract_path.stem
            output_dir = self.contract_path.parent / f"å®¡æ ¸ç»“æœï¼š{original_name}"

        self.output_dir = Path(output_dir)
        self.unpacked_dir = None
        self.doc = None
        self.comments_added = []  # type: List[Dict]
        self.comments_failed = []  # type: List[Dict]
        self.start_time = datetime.now()
        self.contract_analyzer = None  # type: Optional[ContractAnalyzer]
        self.flowchart_mmd_path = None  # type: Optional[Path]
        self.flowchart_image_path = None  # type: Optional[Path]
        self.flowchart_error = None  # type: Optional[str]
        self.flowchart_rendered = False
        self.summary_path = None  # type: Optional[Path]
        self.summary_error = None  # type: Optional[str]
        self.opinion_path = None  # type: Optional[Path]
        self.opinion_error = None  # type: Optional[str]

        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–æ™ºèƒ½åˆ†æå™¨
        if self.enable_analysis:
            try:
                print(f"\nğŸ” åˆå§‹åŒ–æ™ºèƒ½åˆåŒåˆ†æ...")
                self.contract_analyzer = ContractAnalyzer(str(self.contract_path))
                summary = self.contract_analyzer.get_contract_summary()
                print(f"âœ“ åˆåŒç±»å‹: {summary['contract_type']}")
                print(f"âœ“ æ®µè½æ•°é‡: {summary['total_paragraphs']}")
                print(f"âœ“ è¯†åˆ«å­—æ®µ: {summary['found_fields']}ä¸ª")
            except Exception as e:
                print(f"âš ï¸  æ™ºèƒ½åˆ†æåˆå§‹åŒ–å¤±è´¥: {e}")
                print(f"  å°†ç»§ç»­ä½¿ç”¨æ ‡å‡†æ¨¡å¼")

    @staticmethod
    def _strip_risk_level_line(comment_text: str) -> str:
        """
        Remove any line that contains the risk level label from comment text.

        The reviewer name already encodes risk level, so we omit the line
        like "ã€é£é™©ç­‰çº§ã€‘..." from the comment content.
        """
        if not comment_text:
            return comment_text

        lines = comment_text.splitlines()
        kept = [line for line in lines if "é£é™©ç­‰çº§" not in line]

        cleaned = []
        previous_blank = False
        for line in kept:
            if line.strip():
                cleaned.append(line)
                previous_blank = False
            else:
                if not previous_blank:
                    cleaned.append(line)
                previous_blank = True

        while cleaned and not cleaned[0].strip():
            cleaned.pop(0)
        while cleaned and not cleaned[-1].strip():
            cleaned.pop()

        return "\n".join(cleaned)

    def _ensure_output_dir_for_language(self, output_language: Optional[str]) -> None:
        if output_language != "en" or not self.output_dir_default:
            return

        original_name = self.contract_path.stem
        english_dir = self.contract_path.parent / f"Review_Result_{original_name}"
        if self.output_dir == english_dir:
            return

        old_dir = self.output_dir
        self.output_dir = english_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        try:
            if old_dir.exists() and not any(old_dir.iterdir()):
                old_dir.rmdir()
        except Exception:
            pass

    def step0_copy_contract(self) -> bool:
        """
        æ­¥éª¤0: å¤åˆ¶åŸåˆåŒåˆ°å®¡æ ¸ç›®å½•

        å°†åŸå§‹åˆåŒæ–‡ä»¶å¤åˆ¶åˆ°å®¡æ ¸ç»“æœç›®å½•,ä½œä¸ºå¤‡ä»½å’Œå®¡æ ¸åŸºç¡€ã€‚

        Returns:
            bool: æˆåŠŸè¿”å›True,å¤±è´¥è¿”å›False
        """
        print(f"\n{'='*60}")
        print(f"æ­¥éª¤0: å¤åˆ¶åŸåˆåŒ")
        print(f"{'='*60}")
        print(f"ğŸ“„ å¤åˆ¶åŸåˆåŒåˆ°å®¡æ ¸ç›®å½•...")

        try:
            # å¤åˆ¶åŸåˆåŒåˆ°è¾“å‡ºç›®å½•
            target_path = self.output_dir / self.contract_path.name
            shutil.copy2(self.contract_path, target_path)
            print(f"âœ“ å·²å¤åˆ¶åŸåˆåŒ: {target_path.name}")
            print(f"  ğŸ“ å®¡æ ¸ç›®å½•: {self.output_dir}")
            return True
        except Exception as e:
            print(f"âœ— å¤åˆ¶å¤±è´¥: {e}")
            self.comments_failed.append({
                'step': 'å¤åˆ¶åŸåˆåŒ',
                'error': str(e)
            })
            return False

    def step1_unpack(self, unpacked_subdir: str = "unpacked") -> bool:
        """
        æ­¥éª¤1: è§£åŒ…æ–‡æ¡£

        å°†.docxæ–‡ä»¶è§£åŒ…ä¸ºXMLæ–‡ä»¶,ä»¥ä¾¿è¿›è¡Œç¼–è¾‘å’Œæ‰¹æ³¨ã€‚
        è§£åŒ…åçš„æ–‡ä»¶å°†å­˜æ”¾åœ¨è¾“å‡ºç›®å½•ä¸­çš„unpackedå­ç›®å½•ã€‚

        æ³¨æ„:ä½¿ç”¨å®¡æ ¸ç›®å½•ä¸­çš„åˆåŒå‰¯æœ¬,è€Œä¸æ˜¯åŸå§‹åˆåŒ

        Args:
            unpacked_subdir: è§£åŒ…å­ç›®å½•åç§°(ç›¸å¯¹äºoutput_dir)

        Returns:
            bool: æˆåŠŸè¿”å›True,å¤±è´¥è¿”å›False
        """
        print(f"\n{'='*60}")
        print(f"æ­¥éª¤1: è§£åŒ…æ–‡æ¡£")
        print(f"{'='*60}")
        print(f"ğŸ“¦ è§£åŒ…æ–‡æ¡£: {self.contract_path.name}")

        try:
            # ä½¿ç”¨å®¡æ ¸ç›®å½•ä¸­çš„åˆåŒå‰¯æœ¬
            contract_copy = self.output_dir / self.contract_path.name

            # åœ¨è¾“å‡ºç›®å½•ä¸­åˆ›å»ºè§£åŒ…å­ç›®å½•
            self.unpacked_dir = str(self.output_dir / unpacked_subdir)
            unpack_document(str(contract_copy), self.unpacked_dir)
            print(f"âœ“ è§£åŒ…å®Œæˆ: {self.unpacked_dir}")
            return True
        except Exception as e:
            print(f"âœ— è§£åŒ…å¤±è´¥: {e}")
            self.comments_failed.append({
                'step': 'unpack',
                'error': str(e)
            })
            return False

    def step2_initialize(self) -> bool:
        """
        æ­¥éª¤2: åˆå§‹åŒ–Documentå¯¹è±¡

        åˆ›å»ºDocumentå¯¹è±¡,ç”¨äºåç»­çš„æ‰¹æ³¨æ“ä½œã€‚

        Returns:
            bool: æˆåŠŸè¿”å›True,å¤±è´¥è¿”å›False
        """
        print(f"\n{'='*60}")
        print(f"æ­¥éª¤2: åˆå§‹åŒ–æ–‡æ¡£å¯¹è±¡")
        print(f"{'='*60}")
        print(f"ğŸ”§ åˆå§‹åŒ–Documentå¯¹è±¡")

        try:
            self.doc = Document(
                self.unpacked_dir,
                author=self.reviewer_name,
                initials=self.reviewer_initials
            )
            print(f"âœ“ åˆå§‹åŒ–å®Œæˆ")
            print(f"  - å®¡æ ¸äºº: {self.reviewer_name}")
            print(f"  - å·¥ä½œç›®å½•: {self.unpacked_dir}")
            return True
        except Exception as e:
            print(f"âœ— åˆå§‹åŒ–å¤±è´¥: {e}")
            self.comments_failed.append({
                'step': 'initialize',
                'error': str(e)
            })
            return False

    def step3_add_comments(self, comments: List[Dict]) -> bool:
        """
        æ­¥éª¤3: æ‰¹é‡æ·»åŠ æ‰¹æ³¨

        æ ¹æ®æä¾›çš„æ‰¹æ³¨åˆ—è¡¨,æ‰¹é‡æ·»åŠ æ‰¹æ³¨åˆ°æ–‡æ¡£ä¸­ã€‚
        ä½¿ç”¨è·¨èŠ‚ç‚¹æ–‡æœ¬æœç´¢,å¤„ç†æ–‡æœ¬è¢«åˆ†å‰²åœ¨å¤šä¸ªXMLèŠ‚ç‚¹çš„æƒ…å†µã€‚

        æ”¯æŒå¤šç§æœç´¢æ–¹å¼:
        - å•ä¸ªå…³é”®è¯: "search": "åˆåŒç¼–å·:"
        - å¤šä¸ªå…³é”®è¯: "search": ["åˆåŒç¼–å·:", "åè®®ç¼–å·:", "åˆåŒå·:"]
        - ç³»ç»Ÿä¼šä¾æ¬¡å°è¯•æ¯ä¸ªå…³é”®è¯,ç›´åˆ°æ‰¾åˆ°åŒ¹é…

        æ™ºèƒ½ä¼˜åŒ–(å¯ç”¨ enable_smart_keyword_expansion æ—¶):
        - å¦‚æœæä¾›äº†å•ä¸ªå…³é”®è¯,ä¼šè‡ªåŠ¨åŸºäºåˆåŒå†…å®¹æ‰©å±•ä¸ºå¤šä¸ªå…³é”®è¯
        - ä¾‹å¦‚: "åˆåŒç¼–å·:" -> ["åˆåŒç¼–å·:", "åè®®ç¼–å·:", "åˆåŒå·:"]

        Args:
            comments: æ‰¹æ³¨åˆ—è¡¨,æ¯ä¸ªå…ƒç´ åŒ…å«'search'ã€'comment'å’Œå¯é€‰çš„'risk_level'å­—æ®µ
                - æ‰¹æ³¨æ­£æ–‡ä¸éœ€è¦åŒ…å«â€œã€é£é™©ç­‰çº§ã€‘â€è¡Œ(å¦‚åŒ…å«ä¼šè‡ªåŠ¨ç§»é™¤)

        Returns:
            bool: å…¨éƒ¨æˆåŠŸè¿”å›True,éƒ¨åˆ†æˆ–å…¨éƒ¨å¤±è´¥è¿”å›False
        """
        print(f"\n{'='*60}")
        print(f"æ­¥éª¤3: æ·»åŠ æ‰¹æ³¨ (ä½¿ç”¨è·¨èŠ‚ç‚¹æœç´¢ + ç²¾å‡†åŒ¹é…ä¼˜å…ˆ)")
        print(f"{'='*60}")
        print(f"ğŸ’¬ æ·»åŠ  {len(comments)} ä¸ªæ‰¹æ³¨...")

        smart_keywords = None
        if self.contract_analyzer:
            smart_keywords = self.contract_analyzer.generate_smart_search_keywords()
            print(f"\nğŸ§  æ™ºèƒ½æœç´¢å…³é”®è¯å»ºè®®:")
            for field, keywords in list(smart_keywords.items())[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"   {field}: {keywords}")

        all_success = True
        precise_match_count = 0
        fallback_count = 0

        for i, comment_data in enumerate(comments, 1):
            try:
                # è·å–æœç´¢æ–‡æœ¬å’Œæ‰¹æ³¨å†…å®¹
                search_text = comment_data['search']
                comment_text = comment_data['comment']
                comment_text = self._strip_risk_level_line(comment_text)
                risk_level = comment_data.get('risk_level', 'ä¸­é£é™©')  # é»˜è®¤ä¸­é£é™©

                # æ”¯æŒå¤šå…³é”®è¯æœç´¢
                search_keywords = [search_text] if isinstance(search_text, str) else search_text

                # æ™ºèƒ½ä¼˜åŒ–:å¦‚æœå¯ç”¨æ‰©å±•,å°è¯•æ‰©å±•å…³é”®è¯
                if len(search_keywords) == 1 and self.enable_smart_keyword_expansion and smart_keywords:
                    original_keyword = search_keywords[0]
                    # æ ‡å‡†åŒ–å…³é”®è¯(å»é™¤æ ‡ç‚¹ç¬¦å·)è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
                    normalized_original = original_keyword.rstrip(':ï¼š')

                    # æŸ¥æ‰¾åŒ…å«æ ‡å‡†åŒ–å…³é”®è¯çš„å­—æ®µ(ä½¿ç”¨æ›´å®½æ¾çš„åŒ¹é…)
                    for field, keywords in smart_keywords.items():
                        # æ ‡å‡†åŒ–è¯¥å­—æ®µçš„æ‰€æœ‰å…³é”®è¯
                        normalized_keywords = [k.rstrip(':ï¼š') for k in keywords]

                        # å®½æ¾åŒ¹é…:å¦‚æœç”¨æˆ·æœç´¢"åˆåŒç¼–å·",åŒ¹é…åŒ…å«"ç¼–å·"çš„å­—æ®µ
                        if (normalized_original in normalized_keywords or
                            any(normalized_original in nk or nk in normalized_original
                                for nk in normalized_keywords)):
                            # ä½¿ç”¨å®Œæ•´çš„åŸå§‹å…³é”®è¯åˆ—è¡¨
                            search_keywords = keywords
                            print(f"  ğŸ§  æ™ºèƒ½æ‰©å±•: '{original_keyword}' -> {keywords}")
                            break

                # ä½¿ç”¨è·¨èŠ‚ç‚¹æœç´¢æŸ¥æ‰¾ç›®æ ‡æ®µè½ (å…è®¸fallbackåˆ°æ ‡é¢˜)
                para = self.doc.find_paragraph_by_text(search_keywords, allow_fallback=True)

                # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨äº†fallback (æ£€æŸ¥æ®µè½æ˜¯å¦åŒ…å«ä»»ä¸€å…³é”®è¯)
                para_text = self.doc.get_paragraph_text(para)
                used_fallback = not any(keyword in para_text for keyword in search_keywords)

                if used_fallback:
                    fallback_count += 1
                    match_type = "ğŸ”„ Fallbackåˆ°æ ‡é¢˜"
                else:
                    precise_match_count += 1
                    match_type = "ğŸ¯ ç²¾å‡†åŒ¹é…"

                # æ·»åŠ æ‰¹æ³¨(åŒ…å«é£é™©ç­‰çº§)
                comment_id = self.doc.add_comment(
                    start=para,
                    end=para,
                    text=comment_text,
                    risk_level=risk_level
                )
                self.comments_added.append({
                    'id': comment_id,
                    'search': search_keywords[0] if len(search_keywords) == 1 else search_keywords,
                    'risk_level': risk_level,
                    'status': 'success',
                    'fallback_used': used_fallback
                })

                # æ˜¾ç¤ºåŒ¹é…çš„å…³é”®è¯
                matched_keyword = search_keywords[0] if used_fallback else next((k for k in search_keywords if k in para_text), search_keywords[0])
                print(f"âœ“ {i}/{len(comments)}: {match_type} - {matched_keyword[:40]}")

            except Exception as e:
                # æ·»åŠ æ‰¹æ³¨æ—¶å‡ºé”™
                self.comments_failed.append({
                    'search': comment_data.get('search', 'unknown'),
                    'reason': str(e)
                })
                print(f"âœ— {i}/{len(comments)}: å¤±è´¥ - {str(e)[:80]}")

        # æ‰“å°è¯¦ç»†ç»Ÿè®¡
        success_count = len(self.comments_added)
        failed_count = len(self.comments_failed)
        precision_rate = precise_match_count / success_count * 100 if success_count > 0 else 0

        print(f"\næ‰¹æ³¨æ·»åŠ å®Œæˆ:")
        print(f"  âœ“ æˆåŠŸ: {success_count} ä¸ª")
        print(f"    â”œâ”€â”€ ğŸ¯ ç²¾å‡†åŒ¹é…: {precise_match_count} ä¸ª ({precision_rate:.1f}%)")
        print(f"    â””â”€â”€ ğŸ”„ Fallback: {fallback_count} ä¸ª ({100-precision_rate:.1f}%)")
        print(f"  âœ— å¤±è´¥: {failed_count} ä¸ª")

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°90%ç²¾å‡†åŒ¹é…ç›®æ ‡
        if success_count > 0:
            if precision_rate >= 90:
                print(f"\nâœ… ä¼˜ç§€!ç²¾å‡†åŒ¹é…ç‡è¾¾åˆ°{precision_rate:.1f}% (ç›®æ ‡: â‰¥90%)")
            elif precision_rate >= 70:
                print(f"\nâš ï¸ è‰¯å¥½,ä½†ç²¾å‡†åŒ¹é…ç‡{precision_rate:.1f}%æœªè¾¾åˆ°90%ç›®æ ‡")
            else:
                print(f"\nâŒ ç²¾å‡†åŒ¹é…ç‡{precision_rate:.1f}%è¿‡ä½,å»ºè®®ä¼˜åŒ–æœç´¢å…³é”®è¯")

        return failed_count == 0

    def step4_verify(self) -> dict:
        """
        æ­¥éª¤4: éªŒè¯æ‰¹æ³¨

        éªŒè¯æ‰€æœ‰æ‰¹æ³¨æ˜¯å¦æˆåŠŸæ·»åŠ åˆ°æ–‡æ¡£ä¸­,åŒ…æ‹¬:
        - comments.xmlä¸­å­˜åœ¨æ‰¹æ³¨
        - document.xmlä¸­å­˜åœ¨æ‰¹æ³¨å¼•ç”¨

        Returns:
            dict: éªŒè¯ç»“æœå­—å…¸
        """
        print(f"\n{'='*60}")
        print(f"æ­¥éª¤4: éªŒè¯æ‰¹æ³¨")
        print(f"{'='*60}")
        print(f"ğŸ” éªŒè¯æ‰¹æ³¨æ˜¯å¦æˆåŠŸæ·»åŠ ...")

        verification = self.doc.verify_comments()

        print(f"\néªŒè¯ç»“æœ:")
        print(f"  ğŸ“Š æ‰¹æ³¨æ€»æ•°: {verification['total']}")
        print(f"  âœ“ æ–‡æ¡£å¼•ç”¨: {verification['found']}")
        if verification['missing'] > 0:
            print(f"  âœ— ç¼ºå¤±å¼•ç”¨: {verification['missing']}")
            print(f"  âš ï¸  è­¦å‘Š: æœ‰{verification['missing']}ä¸ªæ‰¹æ³¨å¯èƒ½æ— æ³•æ­£å¸¸æ˜¾ç¤º")
        else:
            print(f"  âœ“ æ‰€æœ‰æ‰¹æ³¨å¼•ç”¨å®Œæ•´")

        # æ˜¾ç¤ºæ‰¹æ³¨åˆ—è¡¨é¢„è§ˆ
        if verification['comment_list']:
            print(f"\næ‰¹æ³¨åˆ—è¡¨é¢„è§ˆ (å‰5ä¸ª):")
            for i, comment in enumerate(verification['comment_list'][:5], 1):
                preview = comment['preview'].replace('\n', ' ')
                print(f"  {i}. [{comment['id']}] {comment['author']}: {preview}")
            if len(verification['comment_list']) > 5:
                print(f"  ... è¿˜æœ‰ {len(verification['comment_list']) - 5} ä¸ª")

        return verification

    def step5_save(self, output_filename: str = None, validate: bool = True) -> bool:
        """
        æ­¥éª¤5: ä¿å­˜å¹¶æ‰“åŒ…æ–‡æ¡£

        ä¿å­˜æ‰€æœ‰ä¿®æ”¹å¹¶æ‰“åŒ…ä¸º.docxæ–‡ä»¶ã€‚
        è¾“å‡ºæ–‡ä»¶å°†ä¿å­˜åœ¨è¾“å‡ºç›®å½•ä¸­ã€‚

        Args:
            output_filename: è¾“å‡ºæ–‡ä»¶å(å¦‚"åˆåŒ_å®¡æ ¸ç‰ˆ.docx"),å¦‚æœä¸ºNoneåˆ™ä½¿ç”¨åŸæ–‡ä»¶ååŠ ä¸Š"_reviewed"åç¼€
            validate: æ˜¯å¦éªŒè¯æ–‡æ¡£

        Returns:
            bool: æˆåŠŸè¿”å›True,å¤±è´¥è¿”å›False
        """
        print(f"\n{'='*60}")
        print(f"æ­¥éª¤5: ä¿å­˜å¹¶æ‰“åŒ…æ–‡æ¡£")
        print(f"{'='*60}")
        print(f"ğŸ’¾ ä¿å­˜æ–‡æ¡£...")

        try:
            # ä¿å­˜ä¿®æ”¹åˆ°ä¸´æ—¶ç›®å½•
            self.doc.save(validate=validate)
            print(f"âœ“ æ–‡æ¡£å·²ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•")

            # å¦‚æœæœªæŒ‡å®šè¾“å‡ºæ–‡ä»¶å,ä½¿ç”¨åŸæ–‡ä»¶ååŠ ä¸Š_reviewedåç¼€
            if output_filename is None:
                original_name = self.contract_path.stem
                output_filename = f"{original_name}_reviewed.docx"

            # æ„å»ºå®Œæ•´çš„è¾“å‡ºè·¯å¾„
            output_path = str(self.output_dir / output_filename)

            # æ‰“åŒ…ä¸º.docxæ–‡ä»¶
            pack_document(self.doc.unpacked_path, output_path, validate=False)
            file_size = Path(output_path).stat().st_size / 1024  # KB
            print(f"âœ“ æ–‡æ¡£å·²æ‰“åŒ…: {output_path} ({file_size:.1f} KB)")

            return True
        except Exception as e:
            print(f"âœ— ä¿å­˜å¤±è´¥: {e}")
            print(f"  æç¤º: å¦‚æœé‡åˆ°éªŒè¯é”™è¯¯,å¯ä»¥å°è¯•è®¾ç½® validate=False")
            self.comments_failed.append({
                'step': 'save',
                'error': str(e)
            })
            return False

    def step6_generate_summary(
        self,
        summary_text: Optional[str],
        summary_filename: str = "åˆåŒæ¦‚è¦.docx",
        summary_font: str = "ä»¿å®‹",
    ) -> bool:
        """
        æ­¥éª¤6: åˆåŒæ¦‚è¦æå–

        å°†åˆåŒæ¦‚è¦å†…å®¹ä¿å­˜ä¸ºDOCXå¯Œæ–‡æœ¬,è¾“å‡ºåˆ°å®¡æ ¸ç»“æœç›®å½•ã€‚

        Args:
            summary_text: åˆåŒæ¦‚è¦æ–‡æœ¬(ä¸¥æ ¼æŒ‰æ ¼å¼è¾“å‡º)
            summary_filename: è¾“å‡ºæ–‡ä»¶å
            summary_font: æ¦‚è¦å­—ä½“(é»˜è®¤ä»¿å®‹)

        Returns:
            bool: æˆåŠŸè¿”å›True,å¤±è´¥è¿”å›False
        """
        print(f"\n{'='*60}")
        print(f"æ­¥éª¤6: åˆåŒæ¦‚è¦æå–")
        print(f"{'='*60}")
        print(f"ğŸ§¾ ç”ŸæˆåˆåŒæ¦‚è¦...")

        if not summary_text:
            print("âš ï¸  æœªæä¾›åˆåŒæ¦‚è¦å†…å®¹,è·³è¿‡è¯¥æ­¥éª¤")
            return True

        try:
            content = summary_text.strip()
            if not content.endswith("\n"):
                content += "\n"
            summary_path = self.output_dir / summary_filename
            render_summary_docx(content, summary_path, font_name=summary_font)
            self.summary_path = summary_path
            print(f"âœ“ å·²ç”ŸæˆåˆåŒæ¦‚è¦: {summary_path.name}")
            return True
        except Exception as e:
            self.summary_error = str(e)
            self.comments_failed.append({
                'step': 'summary',
                'error': str(e)
            })
            print(f"âœ— åˆåŒæ¦‚è¦ç”Ÿæˆå¤±è´¥: {e}")
            return False

    def step7_generate_opinion(
        self,
        opinion_text: Optional[str],
        opinion_filename: str = "ç»¼åˆå®¡æ ¸æ„è§.docx",
        opinion_font: str = "ä»¿å®‹",
    ) -> bool:
        """
        æ­¥éª¤7: ç”Ÿæˆç»¼åˆå®¡æ ¸æ„è§

        å°†ç»¼åˆå®¡æ ¸æ„è§ä¿å­˜ä¸ºDOCXå¯Œæ–‡æœ¬,è¾“å‡ºåˆ°å®¡æ ¸ç»“æœç›®å½•ã€‚

        Args:
            opinion_text: ç»¼åˆå®¡æ ¸æ„è§æ–‡æœ¬(ä¸¤æ®µè‡ªç„¶æ®µè½)
            opinion_filename: è¾“å‡ºæ–‡ä»¶å
            opinion_font: æ„è§å­—ä½“(é»˜è®¤ä»¿å®‹)

        Returns:
            bool: æˆåŠŸè¿”å›True,å¤±è´¥è¿”å›False
        """
        print(f"\n{'='*60}")
        print(f"æ­¥éª¤7: ç”Ÿæˆç»¼åˆå®¡æ ¸æ„è§")
        print(f"{'='*60}")
        print(f"ğŸ“ ç”Ÿæˆç»¼åˆå®¡æ ¸æ„è§...")

        if not opinion_text:
            print("âš ï¸  æœªæä¾›ç»¼åˆå®¡æ ¸æ„è§å†…å®¹,è·³è¿‡è¯¥æ­¥éª¤")
            return True

        try:
            content = opinion_text.strip()
            if not content.endswith("\n"):
                content += "\n"
            opinion_path = self.output_dir / opinion_filename
            title_text = "ç»¼åˆå®¡æ ¸æ„è§"
            if self.output_language == "en":
                title_text = "Consolidated Review Opinion"
            render_opinion_docx(
                content,
                opinion_path,
                font_name=opinion_font,
                title_text=title_text,
            )
            self.opinion_path = opinion_path
            print(f"âœ“ å·²ç”Ÿæˆç»¼åˆå®¡æ ¸æ„è§: {opinion_path.name}")
            return True
        except Exception as e:
            self.opinion_error = str(e)
            self.comments_failed.append({
                'step': 'opinion',
                'error': str(e)
            })
            print(f"âœ— ç»¼åˆå®¡æ ¸æ„è§ç”Ÿæˆå¤±è´¥: {e}")
            return False

    def step6_generate_flowchart(
        self,
        mermaid_code: Optional[str],
        mmd_filename: str = "business_flowchart.mmd",
        image_filename: str = "business_flowchart.png",
        render_image: bool = True,
        theme: str = "default",
        background_color: str = "white",
    ) -> bool:
        """
        æ­¥éª¤8: ç”Ÿæˆä¸šåŠ¡æµç¨‹å›¾ (Mermaid)

        å°† Mermaid flowchart ä»£ç ä¿å­˜ä¸º .mmd æ–‡ä»¶å¹¶æ¸²æŸ“ä¸ºå›¾ç‰‡ã€‚
        è¾“å‡ºæ–‡ä»¶ä¿å­˜åœ¨å®¡æ ¸ç»“æœç›®å½•ä¸­ã€‚

        Args:
            mermaid_code: Mermaid flowchart ä»£ç 
            mmd_filename: .mmd æ–‡ä»¶å
            image_filename: å›¾ç‰‡æ–‡ä»¶å(.png/.svg)
            render_image: æ˜¯å¦æ¸²æŸ“å›¾ç‰‡(é»˜è®¤True)
            theme: Mermaid ä¸»é¢˜
            background_color: èƒŒæ™¯è‰²

        Returns:
            bool: æˆåŠŸè¿”å›True,å¤±è´¥è¿”å›False
        """
        print(f"\n{'='*60}")
        print(f"æ­¥éª¤8: ç”Ÿæˆä¸šåŠ¡æµç¨‹å›¾")
        print(f"{'='*60}")
        print(f"ğŸ—ºï¸  ç”Ÿæˆä¸šåŠ¡æµç¨‹å›¾...")

        if not mermaid_code:
            print("âš ï¸  æœªæä¾›Mermaidæµç¨‹å›¾ä»£ç ,è·³è¿‡è¯¥æ­¥éª¤")
            return True

        self.flowchart_error = None
        self.flowchart_rendered = False

        try:
            normalized = normalize_mermaid_code(mermaid_code)
            self.flowchart_mmd_path = write_mermaid_file(
                normalized,
                self.output_dir,
                mmd_filename,
            )
            print(f"âœ“ å·²ä¿å­˜Mermaidæºæ–‡ä»¶: {self.flowchart_mmd_path.name}")

            image_path = self.output_dir / image_filename
            self.flowchart_image_path = image_path
            if render_image:
                if image_path.exists():
                    try:
                        image_path.unlink()
                    except Exception:
                        pass
                render_mermaid_file(
                    self.flowchart_mmd_path,
                    image_path,
                    theme=theme,
                    background_color=background_color,
                )
                self.flowchart_rendered = True
                print(f"âœ“ å·²æ¸²æŸ“æµç¨‹å›¾å›¾ç‰‡: {self.flowchart_image_path.name}")
            else:
                print("âš ï¸  å·²è·³è¿‡å›¾ç‰‡æ¸²æŸ“(ä»…ä¿å­˜.mmdæ–‡ä»¶)")

            return True
        except Exception as e:
            self.flowchart_error = str(e)
            self.comments_failed.append({
                'step': 'flowchart',
                'error': str(e)
            })
            if self.flowchart_image_path and self.flowchart_image_path.exists():
                try:
                    self.flowchart_image_path.unlink()
                except Exception:
                    pass
            print(f"âœ— æµç¨‹å›¾ç”Ÿæˆå¤±è´¥: {e}")
            if isinstance(e, FileNotFoundError):
                print("  æç¤º: è¯·å®‰è£… Mermaid CLI: npm i -g @mermaid-js/mermaid-cli")
            return False

    def step7_generate_report(self, report_filename: str = "review_report.txt") -> bool:
        """
        æ­¥éª¤9: ç”Ÿæˆå®¡æ ¸æŠ¥å‘Š

        ç”Ÿæˆè¯¦ç»†çš„å®¡æ ¸æŠ¥å‘Š,åŒ…æ‹¬:
        - å®¡æ ¸åŸºæœ¬ä¿¡æ¯
        - æ‰¹æ³¨ç»Ÿè®¡
        - å¤±è´¥æ‰¹æ³¨è¯¦æƒ…
        - éªŒè¯ç»“æœ
        - æ‰§è¡Œæ—¶é—´

        æŠ¥å‘Šå°†ä¿å­˜åœ¨è¾“å‡ºç›®å½•ä¸­ã€‚

        Args:
            report_filename: æŠ¥å‘Šæ–‡ä»¶å(å¦‚"review_report.txt")

        Returns:
            bool: æˆåŠŸè¿”å›True,å¤±è´¥è¿”å›False
        """
        print(f"\n{'='*60}")
        print(f"æ­¥éª¤9: ç”Ÿæˆå®¡æ ¸æŠ¥å‘Š")
        print(f"{'='*60}")
        print(f"ğŸ“„ ç”Ÿæˆå®¡æ ¸æŠ¥å‘Š...")

        try:
            duration = (datetime.now() - self.start_time).total_seconds()

            # æ„å»ºå®Œæ•´çš„æŠ¥å‘Šè·¯å¾„
            report_path = str(self.output_dir / report_filename)

            precise_matches = [c for c in self.comments_added if not c.get('fallback_used', False)]
            fallback_matches = [c for c in self.comments_added if c.get('fallback_used', False)]
            comment_failures = [c for c in self.comments_failed if 'search' in c]
            other_failures = [c for c in self.comments_failed if 'search' not in c]
            language = self.output_language or "zh"

            with open(report_path, 'w', encoding='utf-8') as f:
                if language == "en":
                    f.write("=" * 60 + "\n")
                    f.write("Contract Review Comment Report\n")
                    f.write("=" * 60 + "\n\n")

                    f.write("1. Basic Information\n")
                    f.write("-" * 60 + "\n")
                    f.write(f"Reviewer: {self.reviewer_name}\n")
                    f.write(f"Document: {self.contract_path}\n")
                    f.write(f"Review Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"Duration: {duration:.2f} seconds\n")
                    if self.summary_path or self.summary_error:
                        if self.summary_path:
                            f.write(f"Contract Summary: {self.summary_path.name}\n")
                        elif self.summary_error:
                            f.write(f"Contract Summary: Failed ({self.summary_error})\n")
                    if self.opinion_path or self.opinion_error:
                        if self.opinion_path:
                            f.write(f"Consolidated Opinion: {self.opinion_path.name}\n")
                        elif self.opinion_error:
                            f.write(f"Consolidated Opinion: Failed ({self.opinion_error})\n")

                    flowchart_image_path = self.flowchart_image_path
                    if flowchart_image_path is None:
                        candidate = self.output_dir / "business_flowchart.png"
                        if candidate.exists():
                            flowchart_image_path = candidate
                            self.flowchart_image_path = candidate

                    if self.flowchart_mmd_path or self.flowchart_error or self.flowchart_rendered:
                        if self.flowchart_rendered and flowchart_image_path and flowchart_image_path.exists():
                            f.write(f"Flowchart Image: {flowchart_image_path.name}\n")
                        elif self.flowchart_error:
                            f.write(f"Flowchart Image: Failed ({self.flowchart_error})\n")
                        if self.flowchart_mmd_path:
                            f.write(f"Flowchart Source: {self.flowchart_mmd_path.name}\n")
                    f.write("\n")

                    f.write("2. Comment Statistics\n")
                    f.write("-" * 60 + "\n")
                    f.write(f"Added Successfully: {len(self.comments_added)}\n")
                    if len(self.comments_added) > 0:
                        precise_rate = len(precise_matches) / len(self.comments_added) * 100
                        f.write(f"  - Exact Match: {len(precise_matches)} ({precise_rate:.1f}%)\n")
                        f.write(f"  - Fallback: {len(fallback_matches)} ({100-precise_rate:.1f}%)\n")
                    f.write(f"Failed: {len(comment_failures)}\n")
                    total_attempts = len(self.comments_added) + len(comment_failures)
                    success_rate = len(self.comments_added) / total_attempts * 100 if total_attempts else 0
                    f.write(f"Success Rate: {success_rate:.1f}%\n\n")

                    section_index = 3
                    if fallback_matches:
                        f.write(f"{section_index}. Fallback Comment Details\n")
                        f.write("-" * 60 + "\n")
                        f.write(
                            f"{len(fallback_matches)} comments were added to the document title because no exact match was found.\n\n"
                        )
                        for i, comment in enumerate(fallback_matches, 1):
                            f.write(f"{i}. Search Text: {comment['search']}\n")
                            f.write(f"   Risk Level: {comment['risk_level']}\n\n")
                        f.write("Note: These comments may require manual location in the document.\n\n")
                        section_index += 1

                    if comment_failures:
                        f.write(f"{section_index}. Failed Comment Details\n")
                        f.write("-" * 60 + "\n")
                        for i, failed in enumerate(comment_failures, 1):
                            f.write(f"{i}. Search Text: {failed['search']}\n")
                            f.write(f"   Failure Reason: {failed['reason']}\n\n")
                        section_index += 1

                    if other_failures:
                        f.write(f"{section_index}. Other Step Errors\n")
                        f.write("-" * 60 + "\n")
                        for i, failed in enumerate(other_failures, 1):
                            f.write(f"{i}. Step: {failed.get('step', 'unknown')}\n")
                            f.write(f"   Error: {failed['error']}\n\n")
                        section_index += 1

                    verification = self.doc.verify_comments()
                    f.write(f"\n{section_index}. Verification Results\n")
                    f.write("-" * 60 + "\n")
                    f.write(f"Total Comments: {verification['total']}\n")
                    f.write(f"References Found: {verification['found']}\n")
                    f.write(f"Missing References: {verification['missing']}\n")
                    section_index += 1

                    if verification['comment_list']:
                        f.write(f"\n{section_index}. Comment List\n")
                        f.write("-" * 60 + "\n")
                        for i, comment in enumerate(verification['comment_list'], 1):
                            f.write(f"{i}. [ID:{comment['id']}] {comment['author']}\n")
                            f.write(f"   Preview: {comment['preview']}\n\n")

                    f.write("\n" + "=" * 60 + "\n")
                    f.write(f"Report Generated At: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write("=" * 60 + "\n")
                else:
                    f.write("=" * 60 + "\n")
                    f.write("åˆåŒå®¡æ ¸æ‰¹æ³¨æŠ¥å‘Š\n")
                    f.write("=" * 60 + "\n\n")

                    # åŸºæœ¬ä¿¡æ¯
                    f.write("ä¸€ã€åŸºæœ¬ä¿¡æ¯\n")
                    f.write("-" * 60 + "\n")
                    f.write(f"å®¡æ ¸äºº: {self.reviewer_name}\n")
                    f.write(f"æ–‡æ¡£: {self.contract_path}\n")
                    f.write(f"å®¡æ ¸æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"æ‰§è¡Œæ—¶é•¿: {duration:.2f} ç§’\n")
                    if self.summary_path or self.summary_error:
                        if self.summary_path:
                            f.write(f"åˆåŒæ¦‚è¦: {self.summary_path.name}\n")
                        elif self.summary_error:
                            f.write(f"åˆåŒæ¦‚è¦: ç”Ÿæˆå¤±è´¥ ({self.summary_error})\n")
                    if self.opinion_path or self.opinion_error:
                        if self.opinion_path:
                            f.write(f"ç»¼åˆå®¡æ ¸æ„è§: {self.opinion_path.name}\n")
                        elif self.opinion_error:
                            f.write(f"ç»¼åˆå®¡æ ¸æ„è§: ç”Ÿæˆå¤±è´¥ ({self.opinion_error})\n")
                    flowchart_image_path = self.flowchart_image_path
                    if flowchart_image_path is None:
                        candidate = self.output_dir / "business_flowchart.png"
                        if candidate.exists():
                            flowchart_image_path = candidate
                            self.flowchart_image_path = candidate

                    if self.flowchart_mmd_path or self.flowchart_error or self.flowchart_rendered:
                        if self.flowchart_rendered and flowchart_image_path and flowchart_image_path.exists():
                            f.write(f"æµç¨‹å›¾å›¾ç‰‡: {flowchart_image_path.name}\n")
                        elif self.flowchart_error:
                            f.write(f"æµç¨‹å›¾å›¾ç‰‡: ç”Ÿæˆå¤±è´¥ ({self.flowchart_error})\n")
                        if self.flowchart_mmd_path:
                            f.write(f"æµç¨‹å›¾æºç : {self.flowchart_mmd_path.name}\n")
                    f.write("\n")

                    # æ‰¹æ³¨ç»Ÿè®¡
                    f.write("äºŒã€æ‰¹æ³¨ç»Ÿè®¡\n")
                    f.write("-" * 60 + "\n")
                    f.write(f"æˆåŠŸæ·»åŠ : {len(self.comments_added)} ä¸ª\n")

                    if len(self.comments_added) > 0:
                        precise_rate = len(precise_matches) / len(self.comments_added) * 100
                        f.write(f"  â”œâ”€â”€ ç²¾å‡†åŒ¹é…: {len(precise_matches)} ä¸ª ({precise_rate:.1f}%)\n")
                        f.write(f"  â””â”€â”€ Fallback: {len(fallback_matches)} ä¸ª ({100-precise_rate:.1f}%)\n")

                    f.write(f"æ·»åŠ å¤±è´¥: {len(comment_failures)} ä¸ª\n")
                    total_attempts = len(self.comments_added) + len(comment_failures)
                    success_rate = len(self.comments_added) / total_attempts * 100 if total_attempts else 0
                    f.write(f"æˆåŠŸç‡: {success_rate:.1f}%\n\n")

                    section_index = 3
                    if fallback_matches:
                        f.write(f"{_section_cn(section_index)}ã€Fallbackæ‰¹æ³¨è¯¦æƒ…\n")
                        f.write("-" * 60 + "\n")
                        f.write(f"ä»¥ä¸‹{len(fallback_matches)}ä¸ªæ‰¹æ³¨å› æœªæ‰¾åˆ°ç²¾ç¡®åŒ¹é…,å·²æ·»åŠ åˆ°æ–‡æ¡£æ ‡é¢˜:\n\n")
                        for i, comment in enumerate(fallback_matches, 1):
                            f.write(f"{i}. æœç´¢æ–‡æœ¬: {comment['search']}\n")
                            f.write(f"   é£é™©ç­‰çº§: {comment['risk_level']}\n\n")
                        f.write("æ³¨æ„: è¿™äº›æ‰¹æ³¨å¯èƒ½éœ€è¦æ‚¨æ‰‹åŠ¨å®šä½åˆ°ç›¸å…³æ¡æ¬¾ã€‚\n\n")
                        section_index += 1

                    if comment_failures:
                        f.write(f"{_section_cn(section_index)}ã€å¤±è´¥æ‰¹æ³¨è¯¦æƒ…\n")
                        f.write("-" * 60 + "\n")
                        for i, failed in enumerate(comment_failures, 1):
                            f.write(f"{i}. æœç´¢æ–‡æœ¬: {failed['search']}\n")
                            f.write(f"   å¤±è´¥åŸå› : {failed['reason']}\n\n")
                        section_index += 1

                    if other_failures:
                        f.write(f"{_section_cn(section_index)}ã€å…¶ä»–æ­¥éª¤é”™è¯¯\n")
                        f.write("-" * 60 + "\n")
                        for i, failed in enumerate(other_failures, 1):
                            f.write(f"{i}. æ­¥éª¤: {failed.get('step', 'unknown')}\n")
                            f.write(f"   é”™è¯¯ä¿¡æ¯: {failed['error']}\n\n")
                        section_index += 1

                    verification = self.doc.verify_comments()
                    f.write(f"\n{_section_cn(section_index)}ã€éªŒè¯ç»“æœ\n")
                    section_index += 1

                    f.write("-" * 60 + "\n")
                    f.write(f"æ‰¹æ³¨æ€»æ•°: {verification['total']}\n")
                    f.write(f"æ–‡æ¡£å¼•ç”¨: {verification['found']}\n")
                    f.write(f"ç¼ºå¤±å¼•ç”¨: {verification['missing']}\n")

                    if verification['comment_list']:
                        f.write(f"\n{_section_cn(section_index)}ã€æ‰¹æ³¨åˆ—è¡¨\n")

                        f.write("-" * 60 + "\n")
                        for i, comment in enumerate(verification['comment_list'], 1):
                            f.write(f"{i}. [ID:{comment['id']}] {comment['author']}\n")
                            f.write(f"   é¢„è§ˆ: {comment['preview']}\n\n")

                    f.write("\n" + "=" * 60 + "\n")
                    f.write(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write("=" * 60 + "\n")

            print(f"âœ“ æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            return True

        except Exception as e:
            print(f"âœ— æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return False

    def step8_cleanup_output(self,
    output_docx_filename: str,
    report_filename: str) -> Path:
        """
        æ­¥éª¤10: æ¸…ç†è¾“å‡º,åªä¿ç•™æœ€ç»ˆç»“æœæ–‡ä»¶

        åœ¨å®¡æ ¸ç»“æœç›®å½•ä¸­,åˆ é™¤ä¸´æ—¶æ–‡ä»¶,åªä¿ç•™:
        1. åŸåˆåŒ(docx) - å·²åœ¨step0å¤åˆ¶åˆ°å®¡æ ¸ç›®å½•
        2. å®¡æ ¸åçš„åˆåŒ(docx)
        3. å®¡æ ¸æŠ¥å‘Š(txt)

        æ³¨æ„: å®¡æ ¸ç›®å½•æœ¬èº«å°±æ˜¯æœ€ç»ˆè¾“å‡ºç›®å½•,æ— éœ€åˆ›å»ºæ–°ç›®å½•

        Args:
            output_docx_filename: è¾“å‡ºæ–‡æ¡£æ–‡ä»¶å
            report_filename: æŠ¥å‘Šæ–‡ä»¶å

        Returns:
            Path: æœ€ç»ˆè¾“å‡ºç›®å½•è·¯å¾„(å³self.output_dir)
        """
        print(f"\n{'='*60}")
        print(f"æ­¥éª¤10: æ¸…ç†è¾“å‡ºæ–‡ä»¶")
        print(f"{'='*60}")
        print(f"ğŸ§¹ æ¸…ç†ä¸­é—´æ–‡ä»¶,åªä¿ç•™æœ€ç»ˆç»“æœ...")

        try:
            # æœ€ç»ˆè¾“å‡ºç›®å½•å°±æ˜¯å½“å‰å·¥ä½œç›®å½•
            final_output_dir = self.output_dir

            # é‡å‘½åå®¡æ ¸åçš„åˆåŒ
            source_docx = self.output_dir / output_docx_filename
            original_name = self.contract_path.stem
            if self.output_language == "en":
                target_docx = final_output_dir / f"{original_name}_Reviewed.docx"
            else:
                target_docx = final_output_dir / f"{original_name}_å®¡æ ¸ç‰ˆ.docx"

            if source_docx.exists() and source_docx != target_docx:
                shutil.move(str(source_docx), str(target_docx))
                print(f"âœ“ å·²é‡å‘½åå®¡æ ¸åçš„åˆåŒ: {target_docx.name}")
            elif source_docx.exists():
                print(f"âœ“ å®¡æ ¸åçš„åˆåŒ: {target_docx.name}")

            # é‡å‘½åå®¡æ ¸æŠ¥å‘Š
            source_report = self.output_dir / report_filename
            if self.output_language == "en":
                target_report = final_output_dir / "Review_Report.txt"
            else:
                target_report = final_output_dir / "å®¡æ ¸æŠ¥å‘Š.txt"

            if source_report.exists() and source_report != target_report:
                shutil.move(str(source_report), str(target_report))
                print(f"âœ“ å·²é‡å‘½åå®¡æ ¸æŠ¥å‘Š: {target_report.name}")
            elif source_report.exists():
                print(f"âœ“ å®¡æ ¸æŠ¥å‘Š: {target_report.name}")

            # åˆ é™¤unpackedä¸´æ—¶ç›®å½•
            unpacked_dir = self.output_dir / "unpacked"
            if unpacked_dir.exists():
                try:
                    shutil.rmtree(unpacked_dir)
                    print(f"âœ“ å·²åˆ é™¤ä¸´æ—¶ç›®å½•: {unpacked_dir.name}")
                except Exception as e:
                    print(f"âš ï¸  åˆ é™¤ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")

            print(f"\nâœ“ æ¸…ç†å®Œæˆ!")
            print(f"  ğŸ“ æœ€ç»ˆè¾“å‡ºç›®å½•: {final_output_dir}")
            output_files = [
                f"{self.contract_path.name} (åŸåˆåŒ)",
                target_docx.name,
                target_report.name,
            ]

            if self.summary_path and self.summary_path.exists():
                output_files.append(self.summary_path.name)
            if self.opinion_path and self.opinion_path.exists():
                output_files.append(self.opinion_path.name)
            if self.flowchart_rendered and self.flowchart_image_path and self.flowchart_image_path.exists():
                output_files.append(self.flowchart_image_path.name)
            if self.flowchart_mmd_path and self.flowchart_mmd_path.exists():
                output_files.append(self.flowchart_mmd_path.name)

            print(f"  ğŸ“„ åŒ…å«æ–‡ä»¶:")
            for i, filename in enumerate(output_files, 1):
                print(f"    {i}. {filename}")

            return final_output_dir

        except Exception as e:
            print(f"âœ— æ¸…ç†å¤±è´¥: {e}")
            print(f"âš ï¸  æœ€ç»ˆæ–‡ä»¶ä»åœ¨: {self.output_dir}")
            return self.output_dir

    def run_full_workflow(self,
                         comments: List[Dict],
                         output_docx_filename: str = None,
                         report_filename: str = "review_report.txt",
                         validate_doc: bool = False,
                         cleanup: bool = True,
                         parallel_outputs: bool = True,
                         summary_text: Optional[str] = None,
                         summary_filename: str = "åˆåŒæ¦‚è¦.docx",
                         summary_font: str = "ä»¿å®‹",
                         opinion_text: Optional[str] = None,
                         opinion_filename: str = "ç»¼åˆå®¡æ ¸æ„è§.docx",
                         opinion_font: str = "ä»¿å®‹",
                         flowchart_mermaid: Optional[str] = None,
                         flowchart_mmd_filename: str = "business_flowchart.mmd",
                         flowchart_image_filename: str = "business_flowchart.png",
                         render_flowchart: bool = True) -> bool:
        """
        è¿è¡Œå®Œæ•´å·¥ä½œæµç¨‹

        æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰æ­¥éª¤:å¤åˆ¶åŸåˆåŒâ†’è§£åŒ…â†’åˆå§‹åŒ–â†’æ·»åŠ æ‰¹æ³¨â†’éªŒè¯â†’ä¿å­˜â†’ç”ŸæˆåˆåŒæ¦‚è¦â†’ç”Ÿæˆç»¼åˆå®¡æ ¸æ„è§â†’ç”Ÿæˆæµç¨‹å›¾â†’ç”ŸæˆæŠ¥å‘Šâ†’æ¸…ç†è¾“å‡º

        å·¥ä½œæµç¨‹:
        1. åˆ›å»ºå®¡æ ¸ç»“æœç›®å½•: ä¸­æ–‡ä¸ºâ€œå®¡æ ¸ç»“æœï¼šåŸåˆåŒæ–‡ä»¶åâ€ï¼Œè‹±æ–‡ä¸ºâ€œReview_Result_{åŸåˆåŒæ–‡ä»¶å}â€
        2. å¤åˆ¶åŸåˆåŒåˆ°å®¡æ ¸ç›®å½•
        3. åœ¨å®¡æ ¸ç›®å½•ä¸­è¿›è¡Œå®¡æ ¸æ“ä½œ
        4. æ¸…ç†ä¸´æ—¶æ–‡ä»¶,åªä¿ç•™åŸºç¡€æ–‡ä»¶(å¦‚æœ‰æ¦‚è¦/æ„è§/æµç¨‹å›¾è¾“å‡º,ä¼šä¸€å¹¶ä¿ç•™):
           - åŸåˆåŒ(docx)
           - å®¡æ ¸åçš„åˆåŒ(docx)
           - å®¡æ ¸æŠ¥å‘Š(txt)

        Args:
            comments: æ‰¹æ³¨åˆ—è¡¨
            output_docx_filename: è¾“å‡ºæ–‡æ¡£æ–‡ä»¶å(å¦‚"åˆåŒ_å®¡æ ¸ç‰ˆ.docx"),å¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            report_filename: æŠ¥å‘Šæ–‡ä»¶å(å¦‚"review_report.txt")
            validate_doc: æ˜¯å¦éªŒè¯æ–‡æ¡£(é»˜è®¤False,é¿å…OOXMLå…¼å®¹æ€§é—®é¢˜å¯¼è‡´ä¿å­˜å¤±è´¥)
            cleanup: æ˜¯å¦æ¸…ç†ä¸­é—´æ–‡ä»¶(é»˜è®¤True)
            summary_text: åˆåŒæ¦‚è¦æ–‡æœ¬(å¦‚æä¾›åˆ™è¾“å‡ºæ¦‚è¦æ–‡ä»¶)
            summary_filename: åˆåŒæ¦‚è¦æ–‡ä»¶å
            summary_font: åˆåŒæ¦‚è¦å­—ä½“(é»˜è®¤ä»¿å®‹)
            parallel_outputs: æ˜¯å¦å¹¶è¡Œç”Ÿæˆæ¦‚è¦/æ„è§/æµç¨‹å›¾(é»˜è®¤True)
            opinion_text: ç»¼åˆå®¡æ ¸æ„è§æ–‡æœ¬(å¦‚æä¾›åˆ™è¾“å‡ºæ„è§æ–‡ä»¶)
            opinion_filename: ç»¼åˆå®¡æ ¸æ„è§æ–‡ä»¶å
            opinion_font: ç»¼åˆå®¡æ ¸æ„è§å­—ä½“(é»˜è®¤ä»¿å®‹)
            flowchart_mermaid: Mermaidæµç¨‹å›¾ä»£ç (å¦‚æä¾›åˆ™ç”Ÿæˆæµç¨‹å›¾æ–‡ä»¶)
            flowchart_mmd_filename: Mermaidæºæ–‡ä»¶å(.mmd)
            flowchart_image_filename: Mermaidæ¸²æŸ“å›¾ç‰‡å(.png/.svg)
            render_flowchart: æ˜¯å¦æ¸²æŸ“å›¾ç‰‡(é»˜è®¤True)

        Returns:
            bool: å…¨éƒ¨æ­¥éª¤æˆåŠŸè¿”å›True,å¦åˆ™è¿”å›False

        æ³¨æ„:
            é»˜è®¤ç¦ç”¨SchemaéªŒè¯(validate_doc=False),åŸå› :
            1. éƒ¨åˆ†Wordæ–‡æ¡£åŒ…å«ä¸é—´æ–­ç©ºæ ¼(\\xa0),éœ€è¦xml:space='preserve'å±æ€§
            2. éƒ¨åˆ†æ–‡æ¡£å·²æœ‰æ‰¹æ³¨æ‰©å±•æ–‡ä»¶(commentsExtensible.xmlç­‰)
            3. è¿™äº›æ ¼å¼é—®é¢˜ä¸å½±å“Wordæ­£å¸¸ä½¿ç”¨,ä½†ä¼šå¯¼è‡´éªŒè¯å¤±è´¥
            4. å¦‚éœ€ä¸¥æ ¼éªŒè¯,å¯æ‰‹åŠ¨è®¾ç½®validate_doc=True
        """
        print("\n" + "=" * 60)
        print("åˆåŒå®¡æ ¸å·¥ä½œæµç¨‹")
        print("Contract Review Workflow")
        print("=" * 60)

        output_language = _detect_output_language(summary_text, opinion_text, flowchart_mermaid)
        if output_language is None:
            output_language = _detect_output_language_from_contract(self.contract_path)
        if output_language is None:
            output_language = "en"
        self.output_language = output_language
        self._ensure_output_dir_for_language(output_language)
        if output_language == "en":
            if self.reviewer_name == "åˆåŒå®¡æ ¸åŠ©æ‰‹":
                self.reviewer_name = "Contract Review Assistant"
            if self.reviewer_initials == "å®¡æ ¸":
                self.reviewer_initials = "CR"
            if summary_font == "ä»¿å®‹":
                summary_font = "Times New Roman"
            if opinion_font == "ä»¿å®‹":
                opinion_font = "Times New Roman"
            if report_filename == "review_report.txt":
                report_filename = "Review_Report.txt"
        if output_language == "en":
            if summary_filename == "åˆåŒæ¦‚è¦.docx":
                summary_filename = "Contract_Summary.docx"
            if opinion_filename == "ç»¼åˆå®¡æ ¸æ„è§.docx":
                opinion_filename = "Consolidated_Opinion.docx"
        print(f"\nğŸ“ å®¡æ ¸è¾“å‡ºç›®å½•: {self.output_dir}")

        # æ‰§è¡Œæ‰€æœ‰æ­¥éª¤
        success = True

        # æ­¥éª¤0: å¤åˆ¶åŸåˆåŒåˆ°å®¡æ ¸ç›®å½•
        if not self.step0_copy_contract():
            return False

        if not self.step1_unpack():
            return False

        if not self.step2_initialize():
            return False

        if not self.step3_add_comments(comments):
            print("\nâš ï¸  éƒ¨åˆ†æ‰¹æ³¨æ·»åŠ å¤±è´¥,ä½†ç»§ç»­ä¿å­˜...")
            success = False

        verification = self.step4_verify()
        if verification['missing'] > 0:
            print("\nâš ï¸  éªŒè¯å‘ç°é—®é¢˜,ä½†ç»§ç»­ä¿å­˜...")
            success = False

        if not self.step5_save(output_docx_filename, validate=validate_doc):
            return False

        if parallel_outputs and (summary_text or opinion_text or flowchart_mermaid):
            tasks = {}
            with ThreadPoolExecutor(max_workers=3) as executor:
                if summary_text:
                    tasks[executor.submit(
                        self.step6_generate_summary,
                        summary_text,
                        summary_filename,
                        summary_font,
                    )] = "summary"
                if opinion_text:
                    tasks[executor.submit(
                        self.step7_generate_opinion,
                        opinion_text,
                        opinion_filename,
                        opinion_font,
                    )] = "opinion"
                if flowchart_mermaid:
                    tasks[executor.submit(
                        self.step6_generate_flowchart,
                        flowchart_mermaid,
                        flowchart_mmd_filename,
                        flowchart_image_filename,
                        render_flowchart,
                    )] = "flowchart"

                for future in as_completed(tasks):
                    try:
                        ok = future.result()
                    except Exception as e:
                        ok = False
                        step_name = tasks[future]
                        self.comments_failed.append({
                            'step': step_name,
                            'error': str(e)
                        })
                        print(f"âœ— è¾“å‡ºç”Ÿæˆå¤±è´¥: {step_name} - {e}")
                    if not ok:
                        success = False
        else:
            if not self.step6_generate_summary(summary_text, summary_filename, summary_font):
                success = False

            if not self.step7_generate_opinion(opinion_text, opinion_filename, opinion_font):
                success = False

            if not self.step6_generate_flowchart(
                flowchart_mermaid,
                flowchart_mmd_filename,
                flowchart_image_filename,
                render_image=render_flowchart,
            ):
                success = False

        if not self.step7_generate_report(report_filename):
            success = False

        # æ¸…ç†è¾“å‡º,åªä¿ç•™æœ€ç»ˆç»“æœ
        if cleanup:
            # æ„å»ºè¾“å‡ºæ–‡ä»¶å
            if output_docx_filename is None:
                original_name = self.contract_path.stem
                output_docx_filename = f"{original_name}_reviewed.docx"

            # æ‰§è¡Œæ¸…ç†
            final_output_dir = self.step8_cleanup_output(output_docx_filename, report_filename)

            # è·å–æœ€ç»ˆæ–‡ä»¶è·¯å¾„
            original_name = self.contract_path.stem
            if self.output_language == "en":
                final_docx = final_output_dir / f"{original_name}_Reviewed.docx"
                final_report = final_output_dir / "Review_Report.txt"
            else:
                final_docx = final_output_dir / f"{original_name}_å®¡æ ¸ç‰ˆ.docx"
                final_report = final_output_dir / "å®¡æ ¸æŠ¥å‘Š.txt"
        else:
            # ä¸æ¸…ç†,ä½¿ç”¨ä¸´æ—¶ç›®å½•
            final_output_dir = self.output_dir
            if output_docx_filename is None:
                output_docx_filename = f"{self.contract_path.stem}_reviewed.docx"
            final_docx = final_output_dir / output_docx_filename
            final_report = final_output_dir / report_filename

        # æœ€ç»ˆæ€»ç»“
        print("\n" + "=" * 60)
        print("å·¥ä½œæµç¨‹å®Œæˆ!")
        print("=" * 60)
        print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"  âœ“ æˆåŠŸæ·»åŠ æ‰¹æ³¨: {len(self.comments_added)} ä¸ª")
        comment_failures = [c for c in self.comments_failed if 'search' in c]
        print(f"  âœ— æ·»åŠ å¤±è´¥: {len(comment_failures)} ä¸ª")

        # ç»Ÿè®¡ç²¾å‡†åŒ¹é…å’Œfallback
        precise_matches = [c for c in self.comments_added if not c.get('fallback_used', False)]
        fallback_matches = [c for c in self.comments_added if c.get('fallback_used', False)]

        if len(self.comments_added) > 0:
            precise_rate = len(precise_matches) / len(self.comments_added) * 100
            print(f"\nç²¾å‡†åŒ¹é…æƒ…å†µ:")
            print(f"  ğŸ¯ ç²¾å‡†åŒ¹é…: {len(precise_matches)} ä¸ª ({precise_rate:.1f}%)")
            print(f"  ğŸ”„ Fallback: {len(fallback_matches)} ä¸ª ({100-precise_rate:.1f}%)")

        print(f"\nğŸ“ æœ€ç»ˆè¾“å‡º:")
        print(f"  ğŸ“„ å®¡æ ¸åçš„åˆåŒ: {final_docx}")
        print(f"  ğŸ“‹ å®¡æ ¸æŠ¥å‘Š: {final_report}")
        if summary_text:
            if self.summary_path:
                print(f"  ğŸ§¾ åˆåŒæ¦‚è¦: {self.summary_path}")
            elif self.summary_error:
                print(f"  âš ï¸ åˆåŒæ¦‚è¦ç”Ÿæˆå¤±è´¥: {self.summary_error}")
        if opinion_text:
            if self.opinion_path:
                print(f"  ğŸ“ ç»¼åˆå®¡æ ¸æ„è§: {self.opinion_path}")
            elif self.opinion_error:
                print(f"  âš ï¸ ç»¼åˆå®¡æ ¸æ„è§ç”Ÿæˆå¤±è´¥: {self.opinion_error}")
        if flowchart_mermaid:
            if self.flowchart_rendered and self.flowchart_image_path and self.flowchart_image_path.exists():
                print(f"  ğŸ—ºï¸ ä¸šåŠ¡æµç¨‹å›¾: {self.flowchart_image_path}")
            elif self.flowchart_error:
                print(f"  âš ï¸ ä¸šåŠ¡æµç¨‹å›¾ç”Ÿæˆå¤±è´¥: {self.flowchart_error}")
            if self.flowchart_mmd_path:
                print(f"  ğŸ§¾ Mermaidæºæ–‡ä»¶: {self.flowchart_mmd_path}")
        print(f"  ğŸ“‚ è¾“å‡ºç›®å½•: {final_output_dir}")
        print(f"  â±ï¸  æ€»è€—æ—¶: {(datetime.now() - self.start_time).total_seconds():.2f} ç§’")

        if success:
            print(f"\nâœ… æ‰€æœ‰æ­¥éª¤æ‰§è¡ŒæˆåŠŸ!")
        else:
            print(f"\nâš ï¸  å·¥ä½œæµç¨‹å®Œæˆ,ä½†éƒ¨åˆ†æ­¥éª¤å­˜åœ¨é—®é¢˜,è¯·æŸ¥çœ‹æŠ¥å‘Šè¯¦æƒ…ã€‚")

        return success


# ä¾¿æ·å‡½æ•°
def review_contract(contract_path: str,
                   comments: List[Dict],
                   output_docx_filename: str = None,
                   reviewer_name: str = "åˆåŒå®¡æ ¸åŠ©æ‰‹",
                   report_filename: str = "review_report.txt",
                   output_dir: str = None,
                   enable_smart_keyword_expansion: bool = False,
                   summary_text: Optional[str] = None,
                   summary_filename: str = "åˆåŒæ¦‚è¦.docx",
                   summary_font: str = "ä»¿å®‹",
                   opinion_text: Optional[str] = None,
                   opinion_filename: str = "ç»¼åˆå®¡æ ¸æ„è§.docx",
                   opinion_font: str = "ä»¿å®‹",
                   flowchart_mermaid: Optional[str] = None,
                   flowchart_mmd_filename: str = "business_flowchart.mmd",
                   flowchart_image_filename: str = "business_flowchart.png",
                   render_flowchart: bool = True,
                   parallel_outputs: bool = True) -> bool:
    """
    ä¾¿æ·å‡½æ•°:ä¸€é”®å®ŒæˆåˆåŒå®¡æ ¸

    åˆ›å»ºå®¡æ ¸ç»“æœç›®å½•: ä¸­æ–‡ä¸ºâ€œå®¡æ ¸ç»“æœï¼šåŸåˆåŒæ–‡ä»¶åâ€ï¼Œè‹±æ–‡ä¸ºâ€œReview_Result_{åŸåˆåŒæ–‡ä»¶å}â€
    æ‰€æœ‰æ–‡ä»¶(åŸåˆåŒã€å®¡æ ¸åçš„åˆåŒã€å®¡æ ¸æŠ¥å‘Š)å°†ä¿å­˜åœ¨å®¡æ ¸ç»“æœç›®å½•ä¸­ã€‚

    Args:
        contract_path: åˆåŒæ–‡æ¡£è·¯å¾„
        comments: æ‰¹æ³¨åˆ—è¡¨
        output_docx_filename: è¾“å‡ºæ–‡æ¡£æ–‡ä»¶å(å¦‚"åˆåŒ_å®¡æ ¸ç‰ˆ.docx"),å¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        reviewer_name: å®¡æ ¸äººå§“å
        report_filename: æŠ¥å‘Šæ–‡ä»¶å(å¦‚"review_report.txt")
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„(å¦‚æœä¸ºNone,è‡ªåŠ¨åˆ›å»ºé»˜è®¤å®¡æ ¸ç»“æœæ–‡ä»¶å¤¹)
        enable_smart_keyword_expansion: æ˜¯å¦å¯ç”¨æ™ºèƒ½å…³é”®è¯æ‰©å±•(é»˜è®¤False)
        summary_text: åˆåŒæ¦‚è¦æ–‡æœ¬(å¦‚æä¾›åˆ™è¾“å‡ºæ¦‚è¦æ–‡ä»¶)
        summary_filename: åˆåŒæ¦‚è¦æ–‡ä»¶å
        summary_font: åˆåŒæ¦‚è¦å­—ä½“(é»˜è®¤ä»¿å®‹)
        opinion_text: ç»¼åˆå®¡æ ¸æ„è§æ–‡æœ¬(å¦‚æä¾›åˆ™è¾“å‡ºæ„è§æ–‡ä»¶)
        opinion_filename: ç»¼åˆå®¡æ ¸æ„è§æ–‡ä»¶å
        opinion_font: ç»¼åˆå®¡æ ¸æ„è§å­—ä½“(é»˜è®¤ä»¿å®‹)
        flowchart_mermaid: Mermaidæµç¨‹å›¾ä»£ç (å¦‚æä¾›åˆ™ç”Ÿæˆæµç¨‹å›¾æ–‡ä»¶)
        flowchart_mmd_filename: Mermaidæºæ–‡ä»¶å(.mmd)
        flowchart_image_filename: Mermaidæ¸²æŸ“å›¾ç‰‡å(.png/.svg)
        render_flowchart: æ˜¯å¦æ¸²æŸ“å›¾ç‰‡(é»˜è®¤True)
        parallel_outputs: æ˜¯å¦å¹¶è¡Œç”Ÿæˆæ¦‚è¦/æ„è§/æµç¨‹å›¾(é»˜è®¤True)

    Returns:
        bool: æˆåŠŸè¿”å›True,å¤±è´¥è¿”å›False

    Example:
        >>> comments = [{"search": "åˆåŒæ€»ä»·", "comment": "æ‰¹æ³¨å†…å®¹"}]
        >>> review_contract("åˆåŒ.docx", comments, "åˆåŒ_å®¡æ ¸ç‰ˆ.docx")
        >>> # æœ€ç»ˆè¾“å‡º: å®¡æ ¸ç»“æœï¼šåˆåŒ.docx/
        >>> #           â”œâ”€â”€ åˆåŒ.docx (åŸåˆåŒ)
        >>> #           â”œâ”€â”€ åˆåŒ_å®¡æ ¸ç‰ˆ.docx
        >>> #           â”œâ”€â”€ å®¡æ ¸æŠ¥å‘Š.txt
        >>> #           â”œâ”€â”€ åˆåŒæ¦‚è¦.docx (å¦‚æä¾›æ¦‚è¦)
        >>> #           â”œâ”€â”€ ç»¼åˆå®¡æ ¸æ„è§.docx (å¦‚æä¾›æ„è§)
        >>> #           â”œâ”€â”€ business_flowchart.png (å¦‚æä¾›æµç¨‹å›¾)
        >>> #           â””â”€â”€ business_flowchart.mmd (å¦‚æä¾›æµç¨‹å›¾)
        >>> # æˆ–è€…ä½¿ç”¨è‡ªå®šä¹‰è¾“å‡ºç›®å½•
        >>> review_contract("åˆåŒ.docx", comments, output_dir="my_output")
    """
    workflow = ContractReviewWorkflow(
        contract_path,
        reviewer_name,
        output_dir,
        enable_smart_keyword_expansion=enable_smart_keyword_expansion,
    )
    return workflow.run_full_workflow(
        comments,
        output_docx_filename,
        report_filename,
        summary_text=summary_text,
        summary_filename=summary_filename,
        summary_font=summary_font,
        opinion_text=opinion_text,
        opinion_filename=opinion_filename,
        opinion_font=opinion_font,
        flowchart_mermaid=flowchart_mermaid,
        flowchart_mmd_filename=flowchart_mmd_filename,
        flowchart_image_filename=flowchart_image_filename,
        render_flowchart=render_flowchart,
        parallel_outputs=parallel_outputs,
    )


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    print("Contract Review Workflow")
    print("è¿™æ˜¯ä¸€ä¸ªå·¥ä½œæµç¨‹æ¨¡å—,è¯·å¯¼å…¥ä½¿ç”¨:")
    print()
    print("from scripts.workflow import ContractReviewWorkflow")
    print()
    print("comments = [")
    print('    {"search": "å…³é”®è¯", "comment": "æ‰¹æ³¨å†…å®¹"},')
    print("]")
    print()
    print('workflow = ContractReviewWorkflow("åˆåŒ.docx", "å®¡æ ¸äºº")')
    print('workflow.run_full_workflow(comments, "åˆåŒ_å®¡æ ¸ç‰ˆ.docx")')
